plasma[,1]=factor(rep(c("Group 1","Group 2"),each=5))
plot(rbind(c(1,90),c(3,150)),type="n",ylab="Mean",xlab="Time",main="Profiles")
profiles=t(apply(plasma[,2:4],2,tapply,plasma$group,mean))
tmp=apply(profiles,2,lines)
text(x=2.2,y=145,"Group 1")
text(x=2.2,y=114,"Group 2")
cov.pool=(4/5)*(cov(plasma[1:5,2:4])+cov(plasma[6:10,2:4]))/2
diff=profiles[,1]-profiles[,2]
c=cbind(diag(rep(1,2)),rep(0,2))-cbind(rep(0,2),diag(rep(1,2)))
n1=5
n2=5
p=3
n=n1+n2
## are the profiles parallel?
test1=((n1*n2*(n1+n2-p))/((n^2)*(p-1)))*t(c%*%diff)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%diff
test1
qf(0.95,2,7)
## test the equality of parallel profiles
ones=rep(1,3)
test2=((n1*n2*(n1+n2-2))/((n^2)))*(t(ones)%*%diff)^2/(t(ones)%*%cov.pool%*%ones)
test2
qf(0.95,1,8)
## test horizontality of parallel profiles
meanprf=apply(profiles,1,mean)
test3=((n1+n2-p)/(p-1))*t(c%*%meanprf)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%meanprf
test3
qf(0.95,2,7)
#Quantlet SMSprofplasma
data(plasma)
plasma[,1]=factor(rep(c("Group 1","Group 2"),each=5))
#Quantlet SMSprofplasma
data(plasma)
plasma
plasma[,1]=factor(rep(c("Group 1","Group 2"),each=5))
plot(rbind(c(1,90),c(3,150)),type="n",ylab="Mean",xlab="Time",main="Profiles")
#Quantlet SMSprofplasma
data(plasma)
plasma[,1]=factor(rep(c("Group 1","Group 2"),each=5))
plot(rbind(c(1,90),c(3,150)),type="n",ylab="Mean",xlab="Time",main="Profiles")
profiles=t(apply(plasma[,2:4],2,tapply,plasma$group,mean))
tmp=apply(profiles,2,lines)
text(x=2.2,y=145,"Group 1")
text(x=2.2,y=114,"Group 2")
cov.pool=(4/5)*(cov(plasma[1:5,2:4])+cov(plasma[6:10,2:4]))/2
diff=profiles[,1]-profiles[,2]
c=cbind(diag(rep(1,2)),rep(0,2))-cbind(rep(0,2),diag(rep(1,2)))
n1=5
n2=5
p=3
n=n1+n2
## are the profiles parallel?
test1=((n1*n2*(n1+n2-p))/((n^2)*(p-1)))*t(c%*%diff)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%diff
test1
qf(0.95,2,7)
## test the equality of parallel profiles
ones=rep(1,3)
test2=((n1*n2*(n1+n2-2))/((n^2)))*(t(ones)%*%diff)^2/(t(ones)%*%cov.pool%*%ones)
test2
qf(0.95,1,8)
## test horizontality of parallel profiles
meanprf=apply(profiles,1,mean)
test3=((n1+n2-p)/(p-1))*t(c%*%meanprf)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%meanprf
test3
qf(0.95,2,7)
#Quantlet SMSprofplasma
data(plasma)
#plot graph profiles
plasma[,1]=factor(rep(c("Group 1","Group 2"),each=5))
plot(rbind(c(1,90),c(3,150)),type="n",ylab="Mean",xlab="Time",main="Profiles")
profiles=t(apply(plasma[,2:4],2,tapply,plasma$group,mean))
tmp=apply(profiles,2,lines)
text(x=2.2,y=145,"Group 1")
text(x=2.2,y=114,"Group 2")
#test
cov.pool=(4/5)*(cov(plasma[1:5,2:4])+cov(plasma[6:10,2:4]))/2
diff=profiles[,1]-profiles[,2]
c=cbind(diag(rep(1,2)),rep(0,2))-cbind(rep(0,2),diag(rep(1,2)))
n1=5
n2=5
p=3
n=n1+n2
## are the profiles parallel?
test1=((n1*n2*(n1+n2-p))/((n^2)*(p-1)))*t(c%*%diff)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%diff
test1
qf(0.95,2,7)
## test the equality of parallel profiles
ones=rep(1,3)
test2=((n1*n2*(n1+n2-2))/((n^2)))*(t(ones)%*%diff)^2/(t(ones)%*%cov.pool%*%ones)
test2
qf(0.95,1,8)
## test horizontality of parallel profiles
meanprf=apply(profiles,1,mean)
test3=((n1+n2-p)/(p-1))*t(c%*%meanprf)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%meanprf
test3
qf(0.95,2,7)
profiles
plot(rbind(c(1,90),c(3,150)),type="n",ylab="Mean",xlab="Time",main="Profiles")
profiles=t(apply(plasma[,2:4],2,tapply,plasma$group,mean))
tmp=apply(profiles,2,lines)
plasma[,1]=factor(rep(c("Group 1","Group 2"),each=5))
plot(rbind(c(1,90),c(3,150)),type="n",ylab="Mean",xlab="Time",main="Profiles")
profiles=t(apply(plasma[,2:4],2,tapply,plasma$group,mean))
tmp=apply(profiles,2,lines)
text(x=2.2,y=145,"Group 1")
text(x=2.2,y=114,"Group 2")
profiles
test1
qf(0.95,2,7)
## test the equality of parallel profiles
ones=rep(1,3)
test2=((n1*n2*(n1+n2-2))/((n^2)))*(t(ones)%*%diff)^2/(t(ones)%*%cov.pool%*%ones)
test2
qf(0.95,1,8)
## test horizontality of parallel profiles
meanprf=apply(profiles,1,mean)
test3=((n1+n2-p)/(p-1))*t(c%*%meanprf)%*%solve(c%*%cov.pool%*%t(c))%*%c%*%meanprf
test3
qf(0.95,2,7)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
library(car)
library(glmnet)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R78
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
vif(lm(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc))
?l1ce
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
res
opt.t
## split graph.window
layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
vif(lm(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc))
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
## split graph.window
layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
abline(v=opt.t,lty=2)
## plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
vif(lm(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc))
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
## split graph.window
layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
abline(v=opt.t,lty=2)
## plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
vif(lm(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc))
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
## split graph.window
#layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
abline(v=opt.t,lty=2)
## plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
abline(v=opt.t,lty=2)
# coefficients
summary(l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=opt.t))$coefficients
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
## split graph.window
#layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
abline(v=opt.t,lty=2)
## plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
abline(v=opt.t,lty=2)
# coefficients
summary(l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=opt.t))$coefficients
carc
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
## split graph.window
#layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
abline(v=opt.t,lty=2)
## plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
abline(v=opt.t,lty=2)
# coefficients
summary(l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=opt.t))$coefficients
plres$mat
plres$bound
offs
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
res
library(car)
library(lasso2)
library(glmnet)
data(carc)
# convert factors to numeric
carc$R78 = as.numeric(as.character(carc$R78))
carc$R77 = as.numeric(as.character(carc$R77))
carc$C.EU= as.numeric(carc$C=="Europe")
carc$C   = as.numeric(carc$C=="US")
names(carc)[13]="C.US"
res     = l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=(1:40)/40)
# generalized cross-validation - simplification of usual leave-one-out CV
gcv.car = gcv(res)
opt.t   = gcv.car[which.min(gcv.car[,"gcv"]),1]
plres   = plot(res)
## split graph.window
#layout(matrix(c(1,2), 2, 1),heights=c(0.65,0.35))
## plot LASSO
matplot(plres$bound[,"rel.bound"],plres$mat[,-1],type="l",xlim=c(0,1.1),xlab="relative bound",ylab="coefficients",main="lasso for car data set")
offs=rep("",13)
offs[c(1,3,6)]="    "
offs[6]="     "
text(cbind(1.03,coef(res[40])[-1]),paste(offs,labels(res)),cex=0.8,adj=0)
abline(v=opt.t,lty=2)
## plot GCV
plot(gcv.car[,"gcv"]~gcv.car[,1],xlim=c(0,1.1),type="l",ylab="GCV",xlab="relative bound",main="parameter selection")
abline(v=opt.t,lty=2)
# coefficients
summary(l1ce(P~log(M)+R77+R78++H+R+Tr+W+L+T+log(D)+G+C.EU+C.US,data=carc,bound=opt.t))$coefficients
opt.t
if (!require("devtools")) install.packages("devtools")
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
library(e1071)
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
#see the svm.R
#accuracy of SVM model
load('../output/datamatrix.RData')
train_mat<-as.data.frame(datamatrix[,c(-1,-2,-3,-4,-27)])
train_mat$ifwordcorrect<-factor(train_mat$ifwordcorrect)
#split the dataset into training and test data
set.seed(1)
s<-sample(1:2,nrow(train_mat),prob=c(0.8,0.2),replace=T)
trainset<-train_mat[s==1,]
testset<-train_mat[s==2,]
#report training accuracy
load("../output/svm.best.rda")
load("../output/predvalue.rda")
mean(trainset$ifwordcorrect==predvalue)
#report training confusion matrix
library(caret)
confusionMatrix(data=predvalue,reference=trainset$ifwordcorrect)
#retrain the svm on the whole dataset
load("../output/svm.model.rda")
load("../output/svm.model.pred.rda")
mean(svm.model.pred==train_mat$ifwordcorrect)
load("../output/svm.model.pred.rda")
mean(svm.pred==train_mat$ifwordcorrect)
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
setwd("/Users/xiaoxi/Documents/GitHub/Spring2019-Proj4-group10")
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
load('../output/datamatrix.RData')
setwd("/Users/xiaoxi/Documents/GitHub/Spring2019-Proj4-group10/doc")
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
set.seed(1)
s<-sample(1:2,nrow(train_mat),prob=c(0.8,0.2),replace=T)
file_name_vec <- list.files("../data/ground_truth") #100 files in total
file_name_vec
#split the dataset into training and test data
set.seed(1)
s<-sample(1:2,length(file_name_vec),prob=c(0.8,0.2),replace=T)
datamatrix
head(datamatrix)
text.index<-which(s==2)
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
#split the dataset into training and test data
set.seed(1)
head(datamatrix)
s<-sample(1:2,length(file_name_vec),prob=c(0.8,0.2),replace=T)
train.index<-which(s==1)
text.index<-which(s==2)
length(train.index)
length(text.index)
train.index
datamatrix$j %in% train.index
datamatrix<-as.data.frame(datamatrix)
datamatrix$j %in% train.index
sum(datamatrix$j %in% train.index)/298728
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
#split the dataset into training and test data
set.seed(1)
head(datamatrix)
s<-sample(1:2,length(file_name_vec),prob=c(0.8,0.2),replace=T)
train.index<-which(s==1)
text.index<-which(s==2)
datamatrix<-as.data.frame(datamatrix)
datamatrix$ifwordcorrect<-factor(datamatrix$ifwordcorrect)
trainset<-as.data.frame(datamatrix[datamatrix$j %in% train.index,c(-1,-2,-3,-4,-27)])
testset<-as.data.frame(datamatrix[datamatrix$j %in% test.index,c(-1,-2,-3,-4,-27)])
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
#split the dataset into training and test data
set.seed(1)
head(datamatrix)
s<-sample(1:2,length(file_name_vec),prob=c(0.8,0.2),replace=T)
train.index<-which(s==1)
test.index<-which(s==2)
datamatrix<-as.data.frame(datamatrix)
datamatrix$ifwordcorrect<-factor(datamatrix$ifwordcorrect)
trainset<-as.data.frame(datamatrix[datamatrix$j %in% train.index,c(-1,-2,-3,-4,-27)])
testset<-as.data.frame(datamatrix[datamatrix$j %in% test.index,c(-1,-2,-3,-4,-27)])
nrow(trainset)/nrow(datamatrix)
nrow(testset)/nrow(datamatrix)
head(trainset)
library(e1071)
source('../lib/ifCleanToken.R')
load('../output/bigram.RData')
load('../output/datamatrix.RData')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
#split the dataset into training and test data
set.seed(1)
head(datamatrix)
s<-sample(1:2,length(file_name_vec),prob=c(0.8,0.2),replace=T)
train.index<-which(s==1)
test.index<-which(s==2)
datamatrix<-as.data.frame(datamatrix)
datamatrix$ifwordcorrect<-factor(datamatrix$ifwordcorrect)
trainset<-as.data.frame(datamatrix[datamatrix$j %in% train.index,c(-1,-2,-3,-4,-27)])
testset<-as.data.frame(datamatrix[datamatrix$j %in% test.index,c(-1,-2,-3,-4,-27)])
#best model is with C=1, gamma=1
svm.best<-svm(ifwordcorrect~.,data=trainset,cost=1,gamma=1,scale=T,kernel="radial")
save(svm.best, file = "../output/svm.best.rda")
predvalue<-predict(svm.best, testset[,-1])
save(predvalue, file = "../output/predvalue.rda")
#report training confusion matrix
library(caret)
confusionMatrix(data=predvalue,reference=testset$ifwordcorrect)
confusionMatrix(data=predvalue,reference=testset$ifwordcorrect)->svm.table
svm.table
#recall
svm.table[1,1]
#recall
svm.table$table[1,1]
confusionMatrix(data=predvalue,reference=testset$ifwordcorrect,level="0")->svm.table
confusionMatrix(data=predvalue,reference=testset$ifwordcorrect,Positive="0")->svm.table
?confusionMatrix
confusionMatrix(data=predvalue,reference=testset$ifwordcorrect,positive="0")->svm.table
svm.table
#recall
svm.table$table[1,1]/(svm.table$table[1,1]+svm.table$table[2,1])
#recall
svm.table$table[1,1]/(svm.table$table[1,1]+svm.table$table[1,2])
#F-1 score
precision<-svm.table$table[1,1]/(svm.table$table[2,1]+svm.table$table[1,1])
#see the svm.R
#performance of SVM model
load('../output/datamatrix.RData')
#split the dataset into training and test data
set.seed(1)
head(datamatrix)
s<-sample(1:2,length(file_name_vec),prob=c(0.8,0.2),replace=T)
train.index<-which(s==1)
test.index<-which(s==2)
datamatrix<-as.data.frame(datamatrix)
datamatrix$ifwordcorrect<-factor(datamatrix$ifwordcorrect)
trainset<-as.data.frame(datamatrix[datamatrix$j %in% train.index,c(-1,-2,-3,-4,-27)])
testset<-as.data.frame(datamatrix[datamatrix$j %in% test.index,c(-1,-2,-3,-4,-27)])
#report training accuracy
load("../output/svm.best.rda")
load("../output/predvalue.rda")
#report training confusion matrix
library(caret)
confusionMatrix(data=predvalue,reference=testset$ifwordcorrect,positive="0")->svm.table
svm.table
#recall
svm.table$table[1,1]/(svm.table$table[1,1]+svm.table$table[1,2])->recall
recall
#F-1 score
precision<-svm.table$table[1,1]/(svm.table$table[2,1]+svm.table$table[1,1])
precision
f1<-2*precision*recall/(precision+recall)
f1
precision
recall
