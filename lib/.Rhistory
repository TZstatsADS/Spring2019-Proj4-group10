}
}
feature6(word)
[bcdfghjklmnpqrstvxzwyBCDFGHJKLMNPQRSTVXZWY]%in%letters
[:alpha:]
feature8<- function(word){
consec_con<-str_count(word,"[bcdfghjklmnpqrstvxzwyBCDFGHJKLMNPQRSTVXZWY]{6,}")
return(ifelse(consec_con>=1,1,0))
}
feature8(word)
consec_con<-str_count(word,"[bcdfghjklmnpqrstvxzwyBCDFGHJKLMNPQRSTVXZWY]{6,}")
consec_con
word1='aeeiioukjhfuuuieeea'
feature8(word1)
feature8('gfdddrtyieattyybbvcs')
feature8('gfdddrtyieat')
str_count('gfdddrtyieat',"[bcdfghjklmnpqrstvxzwyBCDFGHJKLMNPQRSTVXZWY]{6,}")
str_count('ggfdddrtyieattyybbvcs',"[bcdfghjklmnpqrstvxzwyBCDFGHJKLMNPQRSTVXZWY]{6,}")
word
l<-nchar(word)
trim_word <- substr(word,2,(l-1))
trim_word
non_alnum<-str_count(trim_word,"[^[:alnum:]]")
v
non_alnum
feature9<- function(word){
l<-nchar(word)
trim_word <- substr(word,2,(l-1))
non_alnum<-str_count(trim_word,"[^[:alnum:]]")
return(ifelse(non_alnum>=2,1,0))
}
feature9(word)
split <- strsplit(word, "")[[1]]
split
table(split)
max(table(split))
i <- max(table(split))
i
featureMFS <- function(word){
l <- nchar(word)
split <- strsplit(word, "")[[1]]
i <- max(table(split))
ifelse(i>=3, i/l, 0)
}
featureMFS(word)
featureMFS <- function(word){
l <- nchar(word)
split <- strsplit(word, "")[[1]]
i <- max(table(split))
ifelse(i>=3, i, 0)
}
featureMFS(word)
l_alpha<-length(grep("[[:alpha:]]", strsplit(word,"")[[1]]))
l_alpha
word
l_alpha<-length(grep("[[:alpha:]]", strsplit("AppkkkkfpPle,.#$012%^&","")[[1]]))
l_alpha
feature12NAS <- function(word){
l0 <- length(grep("[[:alpha:]]", strsplit(word,"")[[1]]))
l <- nchar(word)
l1 <- l-l0
return(ifelse(k > l1, 1, 0))
}
feature12NAS(word)
feature12NAS <- function(word){
l1 <- length(grep("[[:alpha:]]", strsplit(word,"")[[1]]))
l <- nchar(word)
l2 <- l-l1
return(ifelse(l1 != 0, l1/l2, 0))
}
feature12NAS(word)
?getBigr
??getBigr
??char_ngrams
unlist(str_split(str_to_lower(word),""))
tokens_ngrams(tokens(c("a b c d e", "c d e f g")), n = 2:3)
??tokens_ngrams
install.packages('tokens_ngrams')
library(rJava)
install.packages('rJava')
library(rJava)
??char_ngrams
??tokens_skipgrams
??ngrams
strsplit(word,"")[[1]]
word
??char_ngrams
token_bigr <- char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
library(stringr)
token_bigr <- char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
library(quanteda)
install.packages('quanteda')
library(quanteda)
token_bigr <- char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
token_bigr
bigr_measure <- getBigr(token_bigr)
??getBigr
library(stringdist)
bigr_measure <- getBigr(token_bigr)
?getBigr
??getBigr
?substr
substr("abcdef", 2, 4)
head(current_tesseract_txt)
current_tesseract_txt[6]
ngram(current_tesseract_txt[6],2)
library(ngram)
ngram(current_tesseract_txt[6],2)
x<-"ABACABB"
ng <- ngram(x, n=2)
x<-"A B A C A B B"
ng <- ngram(x, n=2)
ng
ng@n
ng@str_ptr
ng@strlen
ng@ngl_ptr
ng@ngsize
ng@sl_ptr
??char_ngrams
library(quanteda)
char_ngrams(current_tesseract_txt[6],2)
char_ngrams(current_tesseract_txt[6],2,concatenator = "")
char_ngrams(current_tesseract_txt[6],2,concatenator = " ")
current_tesseract_txt[6]
tokens(c("a b c d e", "c d e f g"))
tokens(current_tesseract_txt[6])
tokens_ngrams(tokens(current_tesseract_txt[6]),2)
tokens_ngrams(tokens(current_tesseract_txt[6]),2,concatenator = "")
tokens_ngrams(tokens(current_tesseract_txt[6]),2,concatenator = " ")
cut_bigram <- function(start_pos, token){
return(substr(token, start = start_pos, stop = start_pos+1))
}
bigram_from_token <- function(input_string){
nb <- nchar(input_string)-1
if(nb >= 2) { bigram <- sapply(1:nb, cut_bigram, input_string) }
else { bigram <- input_string }
return(bigram)
}
bigram_from_token(current_tesseract_txt[6])
char_ngrams(tokens(input_string),2,concatenator = " ")
char_ngrams(strsplit(word,"")[[1]],2,concatenator = " ")
tokens_ngrams(strsplit(word,"")[[1]],2,concatenator = " ")
char_ngrams(strsplit(current_tesseract_txt[6],"")[[1]],2,concatenator = " ")
char_ngrams(strsplit(current_tesseract_txt[6],"")[[1]],2,concatenator = "")
??getBigr
tokens_ngrams(tokens(c("a b c d e", "c d e f g")), n = 2:3)
tokens_skipgrams(toks, n = 2, skip = 0:1, concatenator = " ")
toks <- tokens("insurgents killed in ongoing fighting")
tokens_skipgrams(toks, n = 2, skip = 0:1, concatenator = " ")
char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
load("/Users/yeyejiang/Downloads/feature_train.RData")
View(train_input_unique)
View(train_input_unique)
load("/Users/yeyejiang/Downloads/feature_train.RData")
View(train_input_unique)
load("/Users/yeyejiang/Downloads/Bigram.RData")
View(Bigram)
sum(Bigram$freq)
sum(Bigram$freq)/10000000
file_name_vec
#current_file_name <- sub(".txt","",file_name_vec[i])
train_dir <- "../data/ground_truth"
train_bigram_dir <- paste(train_dir, file_name_vec, sep="")
train_bigram_dir
length(file_name_vec)
file_name_vec[5]
i=5
#current_file_name <- sub(".txt","",file_name_vec[i])
train_dir <- "../data/ground_truth"
train_bigram_dir <- paste(train_dir, file_name_vec[i], sep="")
train_bigram_dir
#current_file_name <- sub(".txt","",file_name_vec[i])
train_dir <- "../data/ground_truth/"
train_bigram_dir <- paste(train_dir, file_name_vec[i], sep="")
train_bigram_dir
head(current_ground_truth_txt)
current_ground_truth_txt
current_file_name <- sub(".txt","",file_name_vec[i])
current_file_name
file_name_vec[5]
paste("../data/ground_truth/",current_file_name,".txt",sep="")
###current_file_name <- sub(".txt","",file_name_vec[i])
#train_dir <- "../data/ground_truth/"
#train_bigram_dir <- paste(train_dir, file_name_vec[i], sep="")
#readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c()
###current_file_name <- sub(".txt","",file_name_vec[i])
#train_dir <- "../data/ground_truth/"
#train_bigram_dir <- paste(train_dir, file_name_vec[i], sep="")
#readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
inputtxt
truth <- c(truth, inputtxt)
truth
inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[1],sep=""), warn=FALSE)
inputtxt
truth <- c(truth, inputtxt)
truth
char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
table(c('a','a','b','b','b'))
table(c('a','a','b','b','b'))[1]
+1
table(c('a','a','b','b','b'))[1]+1
table(c('a','a','b','b','b'))['a']
source('~/Documents/bigram.R')
truth <- c()
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
truth
bigramfreq <- char_ngrams(strsplit(truth,"")[[1]],2,concatenator = "")
bigramfreq
truth
bigramfreq <- char_ngrams(strsplit(truth[996],"")[[1]],2,concatenator = "")
char_ngrams(strsplit(truth[996],"")[[1]],2,concatenator = "")
head(current_tesseract_txt)
strsplit(truth[996],"")[[1]]
toks <- tokens(c(text1 = "the quick brown fox jumped over the lazy dog"))
tokens_ngrams(toks, n = 1:3)
char_ngrams(truth[996], n = 1, concatenator = " ")
char_ngrams(truth[996], n = 1, concatenator = "")
char_ngrams(truth[996], n = 2, concatenator = "")
x<-"ABACABB"
x<-"A B A C A B B"
ngram(x, n=2)
separate(truth[996], sep = " ")
?separate
library(tidyr)
separate(truth[996], sep = " ")
bigrams("The quick brown fox jumped over the lazy dog.")
tokens_ngrams(tokens(input_string),2,concatenator = " ")
tokens_ngrams(tokens(word),2,concatenator = " ")
truth[970:1000]
xxx=scan(paste("../data/ground_truth/",file_name_vec[i],sep=""), what = "")
xxx[1:10]
library(tidyr)
truth <- c()
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
#inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
inputword <- scan(paste("../data/ground_truth/",file_name_vec[i],sep=""), what = "")
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
truth[1:50]
###current_file_name <- sub(".txt","",file_name_vec[i])
#inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
inputword <- scan(paste("../data/ground_truth/",file_name_vec[i],sep=""), what = "")
library(tidyr)
truth <- c()
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
#inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
inputword <- scan(paste("../data/ground_truth/",file_name_vec[i],sep=""), what = "")
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputword)
}
truth[1:100]
bigramfreq <- char_ngrams(strsplit(truth,"")[[1]],2,concatenator = "")
bigramfreq[1:30]
library(tidyr)
truth <- c()
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
head(truth)
head(truth,20)
splittruth <- strsplit(truth, " ")
head(splittruth,30)
splittruth <- unlist(strsplit(truth, " "))
head(splittruth,30)
head(strsplit(splittruth,""))
char_ngrams(strsplit(splittruth,"")[[1:5]],2,concatenator = "")
strsplit(splittruth,"")[[1:5]]
strsplit(splittruth,"")[[1]]
strsplit(splittruth,"")[[2]]
strsplit(splittruth,"")[[1]][[2]]
strsplit(splittruth,"")[[1]][[2]][[3]]
head(strsplit(splittruth,""))
bigramfreq <- char_ngrams(strsplit(splittruth,""),2,concatenator = "")
?lapply
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
x
x <- list(1:10, exp(-3:3), c(TRUE,FALSE,FALSE,TRUE))
x
lapply(x, mean)
bigramfreq <- lapply(strsplit(splittruth,""), char_ngrams(2,concatenator = ""))
head(strsplit(splittruth,""))
char_ngrams(char_ngrams(2,concatenator = "")[[1]], 2,concatenator = "")
char_ngrams(strsplit(splittruth,"")[[1]], 2,concatenator = "")
bigramfreq <- sapply(strsplit(splittruth,""), char_ngrams(2,concatenator = ""))
bigramfreq <- sapply(ascharacter(strsplit(splittruth,"")), char_ngrams(2,concatenator = ""))
head(splittruth,30)
char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
char_ngrams(strsplit(current_tesseract_txt[6],"")[[1]],2,concatenator = "")
current_tesseract_txt[6],"")
current_tesseract_txt[6]
length(splittruth)
length(truth)
?sapply
head(splittruth,30)
demo <- head(splittruth,30)
demo
bigramfreq <- sapply(strsplit(demo,""), char_ngrams(2,concatenator = ""))
char_ngrams(strsplit(demo,""),2,concatenator = ""))
char_ngrams(strsplit(demo,""),2,concatenator = "")
char_ngrams(strsplit(demo,"")[[1]],2,concatenator = "")
bigramfreq <- sapply(strsplit(demo,""), char_ngrams(2,concatenator = ""))
bigramfreq <- lapply(strsplit(demo,""), char_ngrams(2,concatenator = ""))
bigramfreq <- napply(strsplit(demo,""), char_ngrams(2,concatenator = ""))
bigramfreq <- vapply(strsplit(demo,""), char_ngrams(2,concatenator = ""))
bigramfreq <- apply(strsplit(demo,""), 3, char_ngrams(2,concatenator = ""))
strsplit(demo,"")
bigramfreq <- lapply(strsplit(demo,""), char_ngrams(n=2,concatenator = ""))
bigramfreq <- sapply(strsplit(demo,""), char_ngrams(n=2,concatenator = ""))
bigramfreq <- simplify2array(strsplit(demo,""), char_ngrams(n=2,concatenator = ""))
bigramfreq
simplify2array(strsplit(demo,""), char_ngrams(2,concatenator = ""))
char_ngrams(strsplit(demo,"")[[1]],2,concatenator = "")
bigramfreq <- sapply(strsplit(demo,""), function(x) char_ngrams(x, 2,concatenator = ""))
bigramfreq
demo
bigramfreq[[28]]
bigramfreq[[28]]+1
length(bigramfreq[[28]])
length(bigramfreq)
nchar(bigramfreq)
library(tidyr)
truth <- c()
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
#head(truth,15)
splittruth <- unlist(strsplit(truth, " "))
#head(splittruth,30)
bigramfreq <- sapply(strsplit(splittruth,""), function(x) char_ngrams(x, 2,concatenator = ""))
head(bigramfreq)
bigramtable <- table(unlist(bigramfreq))
bigramtable
length(bigramfreq)
#head(splittruth,30)
bigramfreq <- sapply(strsplit(splittruth,""), function(x) char_ngrams(x, 2,concatenator = ""))
source('~/Documents/GitHub/Spring2019-Proj4-group10/lib/bigram.R')
source('~/Documents/GitHub/Spring2019-Proj4-group10/lib/bigram.R', echo=TRUE)
length(splittruth)
sapply(strsplit(splittruth[1:10000],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[1:1000],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[1:100],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[100:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[200:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[300:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[400:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[600:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[800:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[850:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[880:900],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[850:880],""), function(x) char_ngrams(x, 2,concatenator = ""))
splittruth[850:880]
sapply(strsplit(splittruth[860:880],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[870:880],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[870:875],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[875:879],""), function(x) char_ngrams(x, 2,concatenator = ""))
splittruth[875:879]
splittruth[878]
char_ngrams("alter\302\255",2,concatenator = "")
char_ngrams("ddddd302\255",2,concatenator = "")
char_ngrams("ddddd302255",2,concatenator = "")
char_ngrams("dddd5",2,concatenator = "")
strsplit(demo,"")[[1]]
char_ngrams(strsplit('aass',"")[[1]],2,concatenator = "")
char_ngrams(strsplit('alter\302\255',"")[[1]],2,concatenator = "")
tolower('alter\302\255')
char_ngrams(strsplit('alter\302\255',"")[[1]],2,concatenator = "")
?stri_enc_toutf8()
stri_enc_toutf8('alter\302\255')
stri_enc_toutf8
?stringi
library(stringi)
stri_enc_toutf8('alter\302\255')
char_ngrams(strsplit(stri_enc_toutf8('alter\302\255'),"")[[1]],2,concatenator = "")
char_ngrams(strsplit(stri_enc_toutf8('fgj'),"")[[1]],2,concatenator = "")
??stringr
stri_enc_toutf8("alter\302\255", is_unknown_8bit = FALSE, validate = FALSE)
char_ngrams(strsplit(stri_enc_toutf8("alter\302\255", is_unknown_8bit = FALSE, validate = FALSE),"")[[1]],2,concatenator = "")
?readLines
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE, encoding = UTF-8)
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE, encoding = 'UTF-8')
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
#head(truth,15)
splittruth <- unlist(strsplit(truth, " "))
#head(splittruth,30)
bigramfreq <- sapply(strsplit(splittruth[1:10000],""), function(x) char_ngrams(x, 2,concatenator = ""))
#head(splittruth,30)
bigramfreq <- sapply(strsplit(splittruth[1:100],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[1:100],""), function(x) char_ngrams(x, 2,concatenator = ""))
sapply(strsplit(splittruth[100:110],""), function(x) char_ngrams(x, 2,concatenator = ""))
splittruth[100:110]
library(tidyr)
truth <- c()
for(i in c(1:length(file_name_vec))){
###current_file_name <- sub(".txt","",file_name_vec[i])
inputtxt <- readLines(paste("../data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE, encoding = 'UTF-8')
#inputtxt <- readLines(paste("/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/data/ground_truth/",file_name_vec[i],sep=""), warn=FALSE)
truth <- c(truth, inputtxt)
}
#head(truth,15)
splittruth <- unlist(strsplit(truth, " "))
#head(splittruth,30)
bigramfreq <- sapply(strsplit(splittruth,""), function(x) char_ngrams(x, 2,concatenator = ""))
bigramtable <- table(unlist(bigramfreq))
bigramtable
table(c(34,35,46,46,35,35,35))
sort(table(c(34,35,46,46,35,35,35)))
sort(table(c(34,35,46,46,35,35,35)),descreasing = FALSE)
sort(table(c(34,35,46,46,35,35,35)),descreasing = TRUE)
?table
bigramtable['th']
bigramtable['TH']
head(splittruth,30)
#head(truth,15)
splittruth <- unlist(strsplit(tolower(truth), " "))
#head(splittruth,30)
bigramfreq <- sapply(strsplit(splittruth,""), function(x) char_ngrams(x, 2,concatenator = ""))
bigramtable <- table(unlist(bigramfreq))
bigramtable
bigramtable['th']
length(bigramfreq)
head(bigramfreq)
length(unlist(bigramfreq))
## read the ground truth text
current_ground_truth_txt <-  readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
head(current_ground_truth_txt)
length(current_ground_truth_txt)
171*8
*10
171*8*8
*100
length(unlist(bigramfreq))
save(..output/bigram.RData)
save('..output/bigram.RData')
save('../output/bigram.RData')
save(bigramtable, '../output/bigram.RData')
save(bigramtable, './output/bigram.RData')
save(bigramtable, '/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/output/bigram.RData')
save(bigramtable, "./output/bigram.RData")
save(bigramtable, "../output/bigram.RData")
save(bigramtable, "/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/output/bigram.RData")
bigramtable
table(c(34,35,46,46,35,35,35))
matrix(table(c(34,35,46,46,35,35,35)))
save(2, file="/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/output/bigram.RData")
a=2
save(a, file="/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/output/bigram.RData")
bb=table(c(34,35,46,46,35,35,35))
bb
save(bb, file="/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/output/bigram.RData")
save(bigramtable, file="/Users/yeyejiang/Documents/GitHub/Spring2019-Proj4-group10/output/bigram.RData")
save(bigramtable,  file="../output/bigram.RData")
load('../output/bigram.RData)
)
...
defweg
4t653yrtghj
==p-2
quit()
load('../output/bigram.RData')
load('../output/bigram.RData')
word
char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")
bigramtable[char_ngrams(strsplit(word,"")[[1]],2,concatenator = "")]
bigramletters <- tolower(char_ngrams(strsplit(word,"")[[1]],2,concatenator = ""))
bigramtable[bigramletters]
bigramtable[bigramletters]%>%length()
bigramtable[bigramletters][15]
bigramtable[bigramletters]%>%sum()
?sum
sum(bigramtable[bigramletters], na.rm = FALSE)
sum(bigramtable[bigramletters], na.rm = TRUE)
length(word)
nchar(word)
length(bigramletters)
sum(bigramtable[bigramletters], na.rm = TRUE)/length(bigramletters)
word = 'believe'
bigramletters <- tolower(char_ngrams(strsplit(word,"")[[1]],2,concatenator = ""))
sum(bigramtable[bigramletters], na.rm = TRUE)/length(bigramletters)
sum(bigramtable[bigramletters], na.rm = TRUE)/length(bigramletters)/1000
word('a3fgh')
bigramletters <- tolower(char_ngrams(strsplit(word,"")[[1]],2,concatenator = ""))
sum(bigramtable[bigramletters], na.rm = TRUE)/length(bigramletters)/1000
word = 'a3fgh'
bigramletters <- tolower(char_ngrams(strsplit(word,"")[[1]],2,concatenator = ""))
sum(bigramtable[bigramletters], na.rm = TRUE)/length(bigramletters)/1000
